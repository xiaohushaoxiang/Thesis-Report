\chapter{Related Work}

Within the research field of indoor localization, there are generally two approaches that use sensors on the user or machine to localize them, one that is infrastructure dependent and the other that is not. Solutions have also been presented that use a combination to try and improve localization \cite{Gu2019, Correa2017}.
The infrastructure dependent methods imitate the GPS method on a local scale. Here they often replace the GPS constellation with signal-producing devices available within the indoor environment. Examples of such systems are wireless fidelity(Wifi), Bluetooth, wireless sensor networks (WSN), and ultra-wideband (UWB) \cite{Wu2019,Jackermeier2018,Davidson2017}. Position estimation using these systems can be ranged based, leveraging time, angle or received signal strength. They can also be range free using proximity and fingerprinting to estimate position \cite{Correa2017, Tariq2017}. For many of these solutions detailed information on the position of these signal producing external devices is needed for proper estimation. These solutions naturally only in work in buildings with the installed equipment, requiring them to already be present or some initial investment and setup. In some cases this can not be expected, for example within subway systems, due to legal or investment issues, potential vandalism \cite{Torok2014}. \\
The infrastructure independent solution generally leverages sensors that do not need to receive signals from external devices. Such solutions include the use of cameras and inertial sensors. Camera-based systems recognize features in the video feed and combined with known characteristics of the camera and features found in a previous frame, displacement can be determined \cite{Gu2019}. For portable devices continuous use of a camera is not beneficial for battery life, limiting the time duration in which this method can be used \cite{Yang2014}. Furthermore, privacy concerns and computing complexity need to be considered. Another PDR solution uses \ac{IMU} sensors to estimate position. These sensors are \ac{MEMS},  consisting of triaxial orthogonal accelerometers and gyroscopes, and can include a triaxial magnetometer \cite{Yang2014}. These sensors are   relatively small, cheap and have low power consumption \cite{Olsson2016}, and are currently found in many smartphones and increasing in wearable devices.\par

A truly ubiquitous indoor localization will struggle if the used 
solution leads to vendor lock-in due to a specific technology \cite{Torok2014}. To mitigate this, localization infrastructure dependency must be loosened, with completely infrastructure-free solutions having a preference. With this reasoning, this thesis will focus on an infrastructure free solution with the IMU sensors found in most smartphone and wearables as backbone.


\section{Pedestrian Dead Reckoning}
The positioning technique that uses MEMS IMU sensors is called Inertial Pedestrian Dead Reckoning (PDR). Dead reckoning indicates that the output of the system will be the relative position change from a start point \cite{Yu2018}. Within PDR there are two methods, namely Inertial Navigation Systems (INSs) and Step and Heading Systems (SHSs). The INS mechanism integrates the IMU signals directly and is the implementation used most often within research \cite{Diez2018b}. SHS is based on integrating the displacement vectors associated with each step taken during pedestrian locomotion.  Many PDR methods accumulate error with time and are therefore not ideal for long-term pedestrian tracking \cite{Hardegger2012}. Drift reduction methods can be used to try and compensate for this error in order to allow for long-term tracking \cite{MunozDiaz2019a}.
An overview of the different components required by the two PDR systems can be found in \cref{fig:SHS_INS_diagrams}, with further explanation in the following sections.

% With INS the position error grows cubically with time, due to the signal to noise ratio inherent to MEMS IMU sensors \cite{Harle2013}. To compensate for this error, it is preferable that the IMU sensor is mounted on the foot, as will be explained in \cref{sec:INS}. This placement requirement may limit usability. \\

%One advantage of the SHS implementation is that the position error is proportional to the number of steps taken, but without the preference of using foot-based sensors, allowing for other sensor placements \cite{Diez2018b}.

% This section will outline the different PDR methods and focus on an SHS approach to indoor localization.

\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{.8\textwidth}
		\centering
		\includegraphics[trim=20 140 50 80, clip, width=\linewidth]{images/INS_diagram}
		\caption{\ac{INS} pedestrian dead reckoning}
		\label{fig:ins_diagram}
	\end{subfigure}\\
	\begin{subfigure}[t]{0.9\textwidth}
		\centering
		\includegraphics[trim=40 120 40 80, clip,width=\linewidth]{images/shs_diagram}
		\caption{\ac{SHS} pedestrian dead reckoning}
		\label{fig:shs_diagram}
	\end{subfigure}
	\caption{SHS and INS components}
	\label{fig:SHS_INS_diagrams}
\end{figure}
  \newpage   
\subsection{Inertial Navigation System}
\label{sec:INS}

An Inertial Navigation System estimates pose, consisting of orientation and position, using sensor fusion algorithms. These methods are directly applied to the signals generated by MEMS IMU sensors \cite{Wu2019}. Examples of sensor fusion algorithms are the Extended Kalman Filter (EKF) and Complementary Filter (CF) \cite{Kok2017}. Sensor fusion algorithms can estimate position and orientation by integrating acceleration twice and integrating angular velocity once, respectively. This integration, in combination with the effects of noise and bias found in MEMS IMU, causes estimation errors to grow cubically with time for INS \cite{Harle2013}. \\
\newline
A technique frequently used to compensate for the built-up error in INS is zero velocity update (ZUPT) and zero angular update (ZARU) \cite{Harle2013}. It utilizes the ability to detect time periods in which the sensor is stationary during locomotion. Once detected, ZUPT uses the assumption that speed and angular velocity are zero at that time moment \cite{Wu2019,Harle2013}. this a form of pseudo-measurement. This is because the stationary phase is detected, with zero angular and linear velocity being implied by the assumption, which is not an actual measurement. Comparing the assumption with the output of the sensor fusion algorithm, an error can be calculated and used to compensate for the sensor fusion estimate. This process is generally known as a measurement update and can occur every time a stationary period is detected.  Through this measurement update the error grows linearly with number of steps \cite{foxlin2005pedestrian}.\\
\newline
Detecting brief stationary time periods in pedestrian IMU data is done easiest when the sensor is placed on the foot \cite{Diez2018,Davidson2017}. This is because a stationary period is much more pronounced in accelerometer data when the sensor is placed on the foot \cite{Yu2019,Wu2019}.  When walking, a foot periodically returns to a stationary state and stays there for a brief period of time approximately 0.1 to 0.3 seconds \cite{Ren2016a}. This has lead to most \ac{INS} research being foot-sensor based \cite{Diez2018,Wu2019}. A recent deviation from this trend, \citet{Solin2018a} overcome this preference for a foot-based system with a combination of several different pseudo measurements, loop closure, and position fixes, opening up new possibilities for implementing INS in realistic smartphone use cases.\\
%The highest accuracy in PDR has been reached with INS in combination with ZUPT \cite{Hardegger2012}.
Since the majority of research uses foot mounted systems to implement ZUPT for INS \cite{Wu2019}, it suggests that it not yet appropriate for other sensor placements. This is relevant for PDR in realistic smartphone use cases since these devices are generally not carried in one specific way, and if they are, it is doughful if they are placed on the foot. \\ With this information in mind, there are two tracks that can be followed. The first is recreating the solution in \cite{Solin2018a}. The other is determining if the other PDR method is more appropriate. In the next section, the second track will be followed. \\

% Considering this, a focus will be put on implementing a SHS with the potential to handle different carrying modes.
\newpage
\subsection{Step and Heading System}
\label{sec:rw-SHS}
A step and heading system is a form of dead reckoning that detects steps, estimates step length, and the heading in which the pedestrian is moving. This position estimation can be represented by \cite{MunozDiaz2019}
\begin{equation}
	\label{eq:SHS_dynamic_model}
	\left(\begin{array}{l}
		x_t \\
		y_t
	\end{array}\right) 
	=
	\left(\begin{array}{l}
		x_{t-1} \\
		y_{t-1}
	\end{array}\right) 
	+l_{t} \left(\begin{array}{l}
		\cos \left(\theta_{t}\right) \\
		\sin \left(\theta_{t}\right)
	\end{array}\right)
\end{equation}

where $x_{t}$  and  $y_{t}$ represent the position in the $x$-axis and $y$-axis at time  $t$, respectively. $l_{t}$ stands for the step length, while $\theta_{t}$ is the step heading of the pedestrian at time $t$.
There are three components needed to apply this system. These are walk and step detection, step length estimation and step heading estimation.
Similarly to INS, SHS position error is proportional to the number of steps taken. The largest difference is that this error growth does not have a preference of using foot-based sensors, allowing for other sensor placements \cite{Diez2018b}. However, other of sources of error can be introduced due to errors in the detection of steps and their length estimation.  Since other sensor placements ar possible, SHS is the PDR technique often used with smartphones as the base for sensing [\qn]. This indicates that this technique is appropriate for further investigation in answering the thesis research questions.\\
Each component of a step and heading system can be investigated individually in attempt to find the best solution for each. The assumption made is that combining the best solution for each component will lead to the best overall step and heading system. The individual components will be investigated next.

\subsubsection{Walk and Step Detection}
\label{sec:rw - step detection}
Walk detection is determining from sensor data whether a walking activity is being performed. Step detection is deciding when during the walking activity a step is taken. \\
Techniques such as feature classification, frequency domain analysis, and time-domain thresholding can be used to detect the two activities \cite{Yang2014}. An overview of techniques  is  shown in \cref{fig:step_detection_options} and summarized in \cref{tab:step_detection_comparison}. %The reader is referred to \cite{Brajdic2013} for a detailed explanation of each solution.

Naturally, each form of analysis for walk and step detection has its advantages and disadvantages.\\
Time-domain analysis often uses the acceleration norm, making it robust to sensor orientation \cite{Davidson2017}. Its simplest form, thresholding, is trivially simple to implement. The problem with thresholding is that it is difficult to determine the optimal value, as it can vary between users, surfaces, and even shoes \cite{Brajdic2013}. \\
Similar to time-based methods, the periodicity in the norm of acceleration during locomotion is frequently invariant to sensor placement. This therefore also makes frequency analysis robust to sensor orientation. Frequency methods have the disadvantage that they are only able to detect periodic motion. 
For both frequency and time domain-based analysis, it is possible that certain motions, aside from the desired motion, can cross the threshold and generate false positives. In addition, frequency analysis and template matching, a more advanced time based method, will have a certain computational overhead to consider \cite{Davidson2017, Harle2013}. \\
Feature classification methods use features in accelerometer traces to classify steps, using form of machine learning. These method have the advantage that they can determine relations from labeled data automatically, removing a need for humans to define them. This is also a disadvantage as it requires labeled data, the gathering of which can be a labor-intensive process \cite{Bulling2014}. Furthermore, the relationships they determine will depend on the data gathered. This may lead to person dependent performance [\qn]. In addition, certain classification methods may require significant processing power, limiting the platforms on which it can perform [\qn].


\begin{figure}
	\centering
	\includegraphics[trim=0 15 0 20, clip,width=0.7\linewidth]{images/step_detection_options}
	\caption{Overview of walk and step detection methods}
	\label{fig:step_detection_options}
\end{figure}

	\begin{table}
	\centering
	\footnotesize
	\begin{tabularx}{\linewidth}{@{} P{17mm} L}
		\toprule
		\thead[lb]{Technique}	&   \thead[c]{Explanation}	\\
		\midrule			
		Threshold & Acceleration magnitude is monitored for the passing of certain values or sign changes, in the case of Zero Crossing method \cite{Davidson2017,Harle2013}. Typically determines when the foot is on the floor \cite{Harle2013}, but has also been applied to pitch angle of the upper leg, where the sensor has been placed \cite{Diaz2014a}. In some instances, the thresholds are altered adaptively, for example through different motion mode detection or information gathered from the previous step \cite{Wu2019}.\\ \cline{1-2}
		(Windowed) Peak Detection & Recognizes local maximum or minimum on acceleration magnitude caused by foot impact on the floor, often within a sliding window \cite{Susi2013}. Generally combined with thresholding, which is one of the simplest combination used with \ac{SHS} \cite{Davidson2017}. \\ \hline
		Auto-correlation (Template Matching) &  Finds correlation of a signal with a time-shifted copy of itself. It leverages the strong cyclic nature of bipedal locomotion \cite{Harle2013}. Since the lag for the highest correlation is not known beforehand, an interval is often swept and correlation values compared. \\ \hline
		Dynamic Time Warping & Similar to autocorrelation, it measures the similarity between two waveforms from accelerometer data \cite{Davidson2017}, These waveforms can both come from the data or one could be a stride template generated offline. A non linear mapping between the two methods is made, resulting in a DTW distance. A smaller distance indicates higher similarity \cite{Davidson2017}.  \\ \hline
		Short Term Fourier Transform & Transforms acceleration signal of successive windows of data into the frequency domain. For spectral analysis, a subset containing a stride (two steps) is required to determine the frequency \cite{Harle2013}.  \\ \hline
		Wavelet Decomposition & Acceleration magnitude is split into low and high-frequency components, from which the dominant frequency is assumed to be the walking frequency. Iterating this process on the resulting low-frequency signal approximation, a smoother shaped dominant low-frequency signal is generated. The frequency of this signal corresponds to walking cadence \cite{Davidson2017}. \\ \hline	
		Hidden Markov Model & Uses gait cycles segmented into different states of a state machine, to determine if a step has been taken \cite{Ren2016a}. Thresholds can be used to induce a state change. If a full state machine cycle is achieved, a step is detected.\\ \hline
		K Nearest Neighbours & Uses labeled data containing features from successive time windows and compares a new time window with its features. It finds the labeled data whose features are most similar. This new set then recieves its label. \\
		\bottomrule
	\end{tabularx}
	\caption{Overview of different step detection methods}
	\label{tab:step_detection_comparison}
\end{table}

In \cite{Brajdic2013}, a variety of algorithms for both walk detection and step detection on unconstrained smartphones are tested and compared. The paper reviews techniques with different levels of complexity from a variety of different papers. In order to compare the different techniques, \citet{Brajdic2013} collected a large dataset from 27 test subjects leading to 130 recordings was made. Each subject held the smartphone in six different carrying modes: in 
hand in front of user (idle and with device interaction), in a front pocket, in a back pocket and in a handbag or backpack. A ground truth was generated by video recording each session and manually counting the amount of steps taken. Using this dataset a comparison is made between the nine algorithms.
\newline
The paper concludes that for the generated dataset, the best step counting results were obtained using the windowed peak detection, hidden Markov model, and continuous wavelet transform. Each had a median error of about 1.3\%.\\
Considering the relative simplicity of the technique, the authors recommend that windowed peak detection as the most efficient algorithm for step detection. The best walk detection algorithms were thresholds on either standard deviation or signal energy,  short-term Fourier transform, and normalized autocorrelation.\\
\citet{Salvi2018} build upon the conclusions and recommendations of \citet{Brajdic2013}, with the aim of further optimizing the windowed peak detection algorithm and its parameters. The algorithm is based on the approach of \citet{Palshikar2009} and consists of 5 stages run in series. These are pre-processing, filtering, scoring, detection and post processing. An exhaustive grid search across the parameter space was performed to find the optimal set for step detection. Using these parameters, an average accuracy of $95\% \pm 4.5\%$ was reached for the different carrying modes. 

%These results make this approach 


\subsubsection{Step Length Estimation}
In order to generate a displacement vector from step detection, the step length must be estimated. \citet{Collins2013a} found that increasing step speed leads to larger step lengths, while step speed can have slow and spontaneous fluctuations depending on the motion mode. In addition, step size depends on the physical characteristics of the user and on their walk strategy, which can be different per individual \cite{Diez2018}. These discrepancies indicate that using a simple average step length for every pedestrian could result in quick accumulation of error. 

\citet{Diez2018} categorizes step length estimation methods into integration based and model-based methods. \\
Theoretically, the double integration of the IMU acceleration signal is the best approach to step size estimation, using the INS approaches outlined in chapter \secref{sec:INS}. This would give a direct measurement of displacement. It does not require any modeling, assumptions, or person-specific calibration \cite{Diez2018}. However, since it would be an INS approach, it suffers from the same drift problems and would require the same solutions. Therefore this approach benefits from having the sensor to be located on the foot. \\
Analytical models can be made of human mobility based on geometrical relationships of body composition, angles, and displacement of body parts. One of the largest disadvantages of a model-based approach is that human proportions are not uniform, requiring approximations and/or some form of calibration for the model to be accurate.
An overview of different step length estimation methods can be found in \cref{tab:step_length_methods}.

\begin{table}[H]
	\centering
	\textcolor{cyan}{Table with different step length methods}
	\caption{Different Step Length Methods}
	\label{tab:step_length_methods}
\end{table}

\citet{Vezocnik2019} compared different existing step length estimation algorithms. The review focuses on the methods applicable to smartphone use. This means methods that do not require training and do not require the sensor to be placed on the foot. This, therefore, excludes machine learning and INS systems. The models used are either based on an inverted pendulum model or relate predictors to step length. Examples of step length predictors are step frequency and acceleration range within a step. The robustness of the methods was tested by having the smartphone in different carrying modes. This includes front pants pocket, in-hand while reading, in-hand while  swinging carrying arm; and in a bag. Furthermore, a comparison was made between the use of global variables, which are variables constant for every user, and personalized variables, where they are tuned per user. The comparison concludes that for global variables the method from \cite{Tian2016} was best, defined as

\begin{equation}
	\label{eq:Tian2016_sle}
	\text{step size} = K \cdot h \cdot \sqrt{F}.
\end{equation}

Here $K$ is a tunable parameter, $h$ is the height of the user and $F$ is the step frequency. This method reported an average error of  4.59 \% for personalized variables and 6.96 \% for global ones. For personally tuned variables the method of \cite{Weinberg2002} was best. This is an inverted pendulum model in which the human center of mass is used, located approximately at the pelvis. The center of mass rotates as an inverted pendulum when taking a step. This is followed by a forward horizontal displacement when both feet are on the ground \cite{Diez2018}. The model is defined as 

\begin{equation}
	\text{step size} =K \sqrt[4]{A_{\max }-A_{\min }}.
	\label{eq:weinberg_stepsize}
\end{equation}

Here $A_{\max}$ is the largest measured acceleration measured within a step interval, while $A_{\min}$ is the smallest. $K$ is a calibration variable  \cite{Weinberg2002,Diez2018}. The model had an average error of  10.64 \% for global variables and  3.60 \% for personalized \cite{Vezocnik2019}.



\subsubsection{Step Heading Estimation}
Step heading determines the direction of a detected step. It requires the orientation of the sensor in the navigation frame and determining in what direction the sensor is moving in the sensor frame. This provides an estimate in which direction the sensor is moving in the navigation frame.  Step heading estimation is currently the component within SHS whose performance is the most limiting for positioning purposes \cite{Diez2018b, Qian2013,Combettes2017}.\\
Even though the phone orientation may be known accurately, the direction in which the user is moving is not instantly clear. \par
There are two approaches to determining the heading. The first is knowing beforehand what the orientation of the phone is with respect to heading \cite{Tian2016}.  This would constrain the carrying mode that can be used.  With the use of motion classification, this method could be expanded, where different carrying modes can be sensed,which changes the heading accordingly. Heading per carrying mode would need to be derived beforehand, through the training of the necessary model. 

\textcolor{cyan}{this section is not done yet, and so will need completing } \\ \newline
\textcolor{red}{I do not have a comparison of different orientation estimation methods. How do I explain the use of EKF compared to the different possibilities? Should i just add this comparison section?}

\section{Drift Reduction}
\textcolor{cyan}{introduce subject}
\subsection*{Cardinal Heading Aided Heading (CHAH)}
CHAH assumes that most buildings have a square or rectangular construction and that there are four possible headings that the user is likely to walk in \cite{Abdulrahim2011}. These are the \textit{cardinal headings}. Results indicate that the position accuracy can be maintained below 5 meters in periods up to 40 minutes of movement when using a foot based \ac{INS}  \cite{Abdulrahim2011}. This method clearly does not hold when the building does not have this square or rectangular shape, or if the internal structure is not appropriately aligned with the external structure \cite{Davidson2017}.



\subsection*{Topological Map Matching}
Topological map matching is a technique in which the indoor environment is represented by a set of links and nodes, respecting the indoor structure of the building \cite{Davidson2017}. Using this technique the users position estimate is restricted to only lie on a node or link. This constrains the  degrees op freedom an estimate can have. Large open spaces present a challenge since user can walk in what ever direction they please \cite{Davidson2017}. 
%
%This method can be combined with a particle filter \cite{Koivisto2016, Jackermeier2018}. This allows for more constraints, consequently requiring less particles for localization.

\subsection*{Landmark Detection}
Another approach to drift reduction is through the use of landmark detection. Landmarks are locations with a unique footprint detectable in sensor data. When the user visits a landmark and this is detected, the location of the landmark can be used to calibrate the position estimate of the user, hence compensating drift \cite{Diaz2017}. In addition drift reduction by position comparison, landmarks can also be used in determining the user specific parameters of \ac{SHS}, such as step length estimation parameters \cite{Gu2019,Shang2015}. \par
Depending on the sensors available, different landmarks become detectable. Examples of landmarks are doors and stairs \cite{Diaz2017,Gu2019,Torok2014}, but also unique magnetic footprints \cite{MunozDiaz2019}, and electromagentic signal footprints \cite{Gu2019}. Some landmarks can be easily determined beforehand, through the use of available building blueprints \cite{Gu2019}. Others can be detected online \cite{Hardegger2012, Hardegger2016}, not requiring a map representation to be available beforehand, using technique such as \ac{SLAM}. 

One form of landmark detection can be done through activity recognition. In some cases this can be a simple approach, for example applying a threshold on orientation change to determine if a corner has been turned or \cite{Gu2019,Jackermeier2018}. \citet{Hardegger2012} created ActionSLAM, which uses a foot mounted sensor to estimate displacement in combination with location-related actions to compensate any drift buildup. It does not require map information as it used \ac{SLAM}, to produce a map itteratively. In the case of ActionSLAM, the activity recognition was performed manually by annotating from video recordings. The paper indicates a tracking error between a ground truth and the calculated path to be around 1.3 meters. This research is augmented in \citet{Hardegger2016} have recognized the growing trend of wearable technology. They derived a method that used an INS based system in combination with activity recognition through template matching, particle filters, and SLAM to improve both activity recognition and localization. Examples of detected actions are opening a window, picking up a phone and opening a drawer. \\
A different approach was used by \citet{Grzonka2010}, who used a body suit composed of multiple IMU sensors to detect the opening and closing of doors as landmarks, also using a \ac{SLAM} approach for map generation. \citet{Torok2014} have developed DREAR, which is a hidden markov model to detect landmarks using a combination of map information and smartphone sensors, both inertial sensor and magnetometer, to detect when a person is sitting, walking, and taking an escalator.\\
\textcolor{cyan}{above section can be smoother} \\ \newline
\textcolor{cyan}{ I need to refer to the use of particle filters and that for PDR their use is two fold, landmark detection and absolute position estimate}

\subsubsection{Activity Recognition}
Activity recognition is large research field in which methods span a broad range of complexity, from simple thresholding to the use of deep learning techniques such as neural networks and its many variations \cite{Lima2019}. Even the subset of activity recognition that use IMU sensors does not decrease the amount of possibilities significantly.

%TODO add drear as activity recognition

The choice for a particular activity recognition method is often a trade-off between performance and computational complexity \cite{Bulling2014}. Considering the scope of this thesis, certain constraints can be applied, such as that the system should be able to function on a smartphone and must use comparable sensors to those found in such devices, thus MEMS IMUs. \citet{Shoaib2015} have performed an extensive survey that focuses on the online activity recognition solely using mobile phone sensors and onboard processing. Other metrics such as resource consumption were also presented. 30 papers were found to meet the requirements of the review. Within the review they indicate that most commonly used classification methods include Decision Tree, support vector machine (SVM), K-nearest neighbor (KNN) and Naive Bayes, in descending order. A third of the papers were found to use decision trees. All but 6 of the papers had the training process occurring offline. The classification process takes the method generated offline, and uses it online to classify new activities. The authors refrain from listing any performance measures, such as accuracy or precision, since no direct comparison between the different methods is made. \citet{Ahmad2020} specifically focuses on seeing whether smartphone activity recognition techniques are also applicable to smartwatches, and what parameters, including classifiers, work best. Activities to recognize included walking, up-stairs, down-stairs, running, and jogging. Their results indicated that  Decision Trees, SVM and KNN had around 90 percent accuracy a minor difference. \citet{Shoaib2016} show that combining information from both a smartwatch and smartphone, complex human activity recognition is improved compared to when only a smart watch is used. 

\section{Proof of Concept System Overview}
Summarizing the information and the decision made so far, the overall proof of concept can be found in \cref{fig:system_design}.
\textcolor{cyan}{further explanation}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth]{images/system_design}
	\caption{Overview of proof of concept SHS-PF with activity recognition from wearable device}
	\label{fig:system_design}
\end{figure}



% The Beauregard implementation introduced backtracking, whereby the filter kept a limited history of each particle’s ancestors to allow deletion of an entire trajectory when a particle was killed due to a wall constraint. This is a variant of backward belief propagation also used by Rai et al. [23] and is useful to improve position estimates made in the past when live positioning is not a requirement.
